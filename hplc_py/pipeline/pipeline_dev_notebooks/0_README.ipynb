{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "date: 2024-04-10\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "This document contains an index of an effort to deconvolute a chromatographic signal.\n",
    "\n",
    "The signal is complex, heavily convoluted, and possesses a drifting baseline.\n",
    "\n",
    "The signal is of Chris Ringland Shiraz, recorded (TODO: fill in metadata)\n",
    "\n",
    "The notebooks will appear in the order of granularity, or of problem solving. Specifically, the first (several?)  will pertain to problem identification, then solving.\n",
    "\n",
    "The document (s) will be living, that is, if subjects addressed in one notebook turn out to not be relevant to the final solution, they will be edited/removed. Once a solution is reached, a final review will be conducted, and then the document will be archived.\n",
    "\n",
    "TODO: identify problem\n",
    "TODO: find solution\n",
    "TODO: final review\n",
    "TODO: archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "## Chromatography methods\n",
    "\n",
    "- \"Liquid Chromatography - Fundamentals and Instrumentation\", @fanali_2023\n",
    "- \"HPLC and UHPLC for practicing scientists\", @dong_2019\n",
    "- \"Chromatography: principles and instrumentation\", @vitha_2017c\n",
    "\n",
    "## Digital Signal Processing\n",
    "\n",
    "- \"The Scientist and Engineer's Guide to Digital Signal Processing\" - @smith_2024\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes from Development\n",
    "\n",
    "2. 2024-04-24 22:45:55: this project needs to proceed in a chapter and subchapter form if its going to become publishable. Therefore, chapter 1 would be experimental, chapter 2 would be ETL, chapter 3 will be signal preprocessing, chapter 4 can be statistical analysis. Each section will be its own notebook, thus enabling quick access to the topic, and expansion on each at a later date if deemed necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Impasse\n",
    "\n",
    "There are too many competing factors currently. They are as follows:\n",
    "\n",
    "1. [ ] Need to increase the resolution to expose peaks which are not being deconvolved correctly.\n",
    "2. [ ] I dont actually have an up to date deconvolution transformer.\n",
    "  1. [ ] need to determine how to integrate windowing.\n",
    "3. [ ] I dont have an adequate method of optimizing the sharpening algorithm transformers\n",
    "  1. [ ] the goal is to sharpen as much as possible without dipping below the baseline. To do that I need to define an optimization algorithm that defines optimiality when n+1 contains less than zero.\n",
    "4. [ ] I dont have an adequate API for comparing input, intermediate, and output arays. Essentially I need a wrapping class that extracts the data and plots from each intermediate step in the pipeline and exposes them. I have already partially developed this, but Pipeline does already provide this functionality through the `steps` dict. All i need is something to define the order, clearly identifying the original input X, and turning the dict into attributes.\n",
    "5. [ ] The \"next to each other\" window bug is still present. To solve this, I need to add a back search into the window assignment algorithm such that when it assigns a new window, check if the previous iteration is n-1, and if so, set the current iteration to the current window rather than moving on. seems like a whole thing though.\n",
    "6. [ ] I dont seem to know how to solve problems, generally speaking. \n",
    "\n",
    "I think 2. is actually the most dire. To solve it immediately, I can just run the current data I have through. To do this, and to test continuity, i will develop an ecosystem of notebooks for testing purposes. For example, [this notebook](./test_deconvolution_pipeline.ipynb) will demonstrate the 'production' deconvolution pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
