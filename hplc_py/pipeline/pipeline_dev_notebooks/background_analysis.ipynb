{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the results are collected, I need to define an analysis class. it needs to perform the following calculations:\n",
    "\n",
    "1. background 1st and second deriv\n",
    "  - Turns out this isnt as easy as thought. need to decide between finite difference or polynomial fit\n",
    "2. AUC of input and adjusted signal:\n",
    "  1. py_hplc approximate AUC by summing the y values, but that doesnt include area in between the points. So \n",
    "  the lower the sampling rate, the less accurate that is. Good first start though.\n",
    "3. num peaks per peak window\n",
    "4. window start, finish, length\n",
    "\n",
    "Also want to seperate the times into quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy.polynomial import Polynomial\n",
    "from numpy.polynomial import Legendre\n",
    "\n",
    "\n",
    "class BackgroundAnalyser:\n",
    "    \"\"\"\n",
    "    Main intent is to observe the 'roughness' of the estimated background via the SNIP\n",
    "    method, providing a measure of overfit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, results: Results):\n",
    "        self.results = results\n",
    "        self.background = self.results.signals.filter(pl.col(\"n_iter\") == 40).select(\n",
    "            pl.col(\"time\"), pl.col(\"background\")\n",
    "        )\n",
    "        self.x = np.linspace(0, 1, len(self.background))\n",
    "        self.y = self.background.select(\"background\").to_numpy().ravel()\n",
    "        pass\n",
    "\n",
    "    def finite_diffs(self):\n",
    "        \"\"\"\n",
    "        Calculate the first and second central differences. The end points are handled as forward and back difference, respectively.\n",
    "        \"\"\"\n",
    "        idx = \"idx\"\n",
    "        x = str(Signals.time)\n",
    "        y = str(Signals.background)\n",
    "\n",
    "        self.background_diffs: pl.DataFrame = (\n",
    "            self.results.signals.with_row_index(idx)\n",
    "            .select(\n",
    "                pl.col(\"n_iter\"),\n",
    "                pl.col(x),\n",
    "                pl.col(y),\n",
    "                pl.col(y).diff().alias(\"first_diff\"),\n",
    "                pl.col(y).diff().diff().alias(\"second_diff\"),\n",
    "            )\n",
    "            .melt(id_vars=[\"n_iter\", x], variable_name=\"diff\", value_name=\"values\")\n",
    "        )\n",
    "\n",
    "        display(\n",
    "            sns.relplot(\n",
    "                data=self.background_diffs, x=x, y=y, col=\"n_iter\", by=\"diff\", colwrap=2\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def fit_background_polynomial(self):\n",
    "        \"\"\"\n",
    "        Approximate the background with a polynomial fit.\n",
    "\n",
    "        The result is poor because the shape of the background is essentially two convoluted gaussian peaks,\n",
    "        requiring a polynomial degree > 200 to fit the general shape.\n",
    "\n",
    "        least squares fit assessment is done through observation of:\n",
    "        - R squared\n",
    "        - F score\n",
    "        - Root Mean Square Error\n",
    "\n",
    "        These are base on Sum of Squares Total and Sum of Squares Error. See <https://www.theanalysisfactor.com/assessing-the-fit-of-regression-models/#:~:text=Three%20statistics%20are%20used%20in,of%20Squares%20Error%20(SSE)>\n",
    "\n",
    "        NOTE: currently only calculates R^2, and does nothing with it.\n",
    "\n",
    "        TODO: determine how to store the results, and then what to do with them. Probably do average absolute deviation from the fitted line.\n",
    "        \"\"\"\n",
    "\n",
    "        c: np.polynomial.legendre.Legendre\n",
    "        out_diagnostics: list\n",
    "        c, out_diagnostics = Legendre.fit(x=self.x, y=self.y, deg=200, full=True)\n",
    "        fitted_background = c.linspace(len(self.background))\n",
    "\n",
    "        # resid: Residual Sum of Squares - \\sum^n_{i=1} { (y_i - f(x_i))^2 }\n",
    "\n",
    "        diagnostics_keys = [\"resid\", \"rank\", \"sv\", \"rcond\"]\n",
    "\n",
    "        diagnostics = dict(zip(diagnostics_keys, out_diagnostics))\n",
    "\n",
    "        df = (\n",
    "            self.background.with_columns(\n",
    "                pl.Series(name=\"fitted_background\", values=fitted_background[1])\n",
    "            )\n",
    "            .melt(id_vars=\"time\", variable_name=\"f\", value_name=\"values\")\n",
    "            .to_pandas()\n",
    "        )\n",
    "\n",
    "        # R^2 = 1 - RSS / TSS\n",
    "\n",
    "        # TSS\n",
    "\n",
    "        tss = ((self.y - self.y.mean()) ** 2).sum()\n",
    "\n",
    "        # RSS\n",
    "\n",
    "        rss = diagnostics[\"resid\"]\n",
    "\n",
    "        r_2 = 1 - (rss / tss)\n",
    "\n",
    "        # display(diagnostics)\n",
    "        display(df)\n",
    "        display(r_2)\n",
    "        display(sns.lineplot(data=df, x=\"time\", y=\"values\", hue=\"f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background_analyser = BackgroundAnalyser(results=initial_results)\n",
    "# analyzer.analyse_background()\n",
    "# background_analyser.fit_background_polynomial()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
